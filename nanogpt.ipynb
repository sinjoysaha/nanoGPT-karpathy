{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    datefmt=\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(fpath=\"\") -> str:\n",
    "    import os\n",
    "    if fpath==\"\" or fpath==\"tinyshakespeare\":\n",
    "        fpath = os.path.join(\"data\", \"tinyshakespeare\", \"input.txt\") # data/tinysharespeare/input.txt\n",
    "    if os.path.exists(fpath):\n",
    "        logging.info(f\"Reading: {fpath}\")\n",
    "        with open(fpath) as f:\n",
    "            text = f.read()\n",
    "\n",
    "        return text\n",
    "    \n",
    "    else:\n",
    "        logging.error(f\"File not found: {fpath}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:05:07 - INFO - Reading: data\\tinyshakespeare\\input.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = read_input(\"tinyshakespeare\")\n",
    "total_len = len(text)\n",
    "total_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_set(train_split=0.9):\n",
    "    train_text = text[:int(total_len*train_split)]\n",
    "    val_text = text[int(total_len*train_split):]\n",
    "    return train_text, val_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003854, 111540)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text, val_text = get_train_val_set()\n",
    "len(train_text), len(val_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\", 65)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = set(train_text)\n",
    "vocab_size = len(char_set)\n",
    "''.join(sorted(char_set)), vocab_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from string to list of int \n",
    "stoi = {ch: i for i, ch in enumerate(char_set)}\n",
    "\n",
    "# Reverse mapping from list of int to string\n",
    "itos = {i: ch for i, ch in enumerate(char_set)}\n",
    "\n",
    "# Tokenize \n",
    "encode = lambda s: [stoi[ch] for ch in s] # Handle unknown chars\n",
    "decode = lambda li: ''.join([itos[i] for i in li])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48, 62, 55, 17, 48, 18, 12, 12, 36, 63, 39, 36, 50, 12, 54, 55]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hi!\\nhello world!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test encode\n",
    "test_tk = encode(\"hi!\\nhello world!\")\n",
    "print(test_tk)\n",
    "# test decode\n",
    "decode(test_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_text = encode(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c998e0ae665eb6f793e1208786b98241f4e90916acb157f83d0b93d14aab62b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
